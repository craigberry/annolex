{% extends "start.html" %}
{% block content %}

<div id="main">
<p align="center">AnnoLex Beta v0.11 -- 28 February 2010</p>
<table  width="600">
<tr><td>
        <h2>What is AnnoLex?</h2>
        <p>AnnoLex is a collaborative data curation tool
for lemmatized and morphosyntactically tagged textual data. It is built using
the Django framework, which is written in Python, and it stores its data
in a MySQL database. Annolex is being developed by Craig Berry and Martin Mueller
under a grant from Academic Research Technologies at Northwestern
University.</p>
        <p>The data currently contained in Annolex consist of 282
Early Modern English plays (~ six million words) by authors other than
Shakespeare. The source files are SGML encoded texts transcribed by the
Text Creation Partnership from the microfilm images of Early English
Books Online. As part of the MONK project, these files were transformed
into TEI-P5 XML files through procedures designed and implemented by
Stephen Ramsay and Brian Pytlik Zillig, then tokenized, lemmatized, and
morphosyntactically annotated with Morphadorner, a Natural Language
Processing Toolkit written by Phil Burns.  </p>
        <p>The transcriptions from microfilm images contain many errors
and omissions. Machine-generated tokenization, lemmatization, and
morphosyntactic annotation also add errors. Many  of these errors can
be corrected with high degrees of confidence and do not require
consultation  of the source files. Some of them do.  AnnoLex is designed
to support such corrections as the work of many hands at different times
and in different places. </p>
        <h2>What can you do with Annolex?</h2>
        <p>The potential of Annolex is best seen by looking at its
'verticalized' representation of the underlying text. Every word
occurrence or token in the text is a  data row, consisting of: </p>
       <ol>
           <li>a unique ID for the word token</li>
           <li>the spelling of the token</li>
           <li>the 35 characters before the token</li>
           <li>the 35 characters following the token</li>
           <li>the lemma assigned to the token</li>
           <li>the part-of-speech (POS) tag assigned to the token</li>
       </ol>
        <p>Users can select token ranges by spelling, POS tag, lemma,
work, or unique word identifier, and sort return lists by those criteria. Because
errors for the most part are not randomly distributed, it is possible to
design 'error forcing' routines or searches that retrieve lists in which
certain kinds of error are expected to cluster.  </p>
        <h2>How do you correct an error?</h2>
        <p>In order to correct an error, you must have a user account
and log in to AnnoLex. A correction does not immediately overwrite the current text.
In the "Edit Word" form you suggest a correction for the spelling, lemma,
and/or POS tag of a word. When you click "Save," the suggestion is entered as a user transaction
into a data row in a correction table that records:  </p>
        <ol>
            <li>your user id</li>
            <li>a time stamp for the transaction</li>
            <li>the token id associated with the correction</li>
            <li>the spelling, lemma and/or POS tag that is suggested as the correction (you
            may suggest one, two, or all three in a single transaction)</li>
            <li>an optional annotation indicating the rationale for the change</li>
        </ol>
        <p>User suggestions are subject to editorial review. A user with elevated privileges may
review and approve corrections using the "Review" screen. Any user may see suggested 
corrections in the same place.</p>
        <p>Notice that once there is a substantial error list, its
analysis will provide very useful guidance to identifying likely errors
elsewhere.</p>
        <h2>What errors are most worth fixing?</h2>
        <p>The most irritating and the most easily fixed errors in the
texts result from incomplete transcriptions -- letters or words that the
transcribers could not identify in the page images and marked as such.
In the six million words of the 283 plays (not counting a million
punctuation marks), there are are at least 60,000 errors of that kind.
One in a hundred words has something wrong with it. In the 35,000 words
of the two parts of Tamburlaine almost 1,000 words (~3%) are
incompletely transcribed or omitted altogether. According to the <i>New
York Times</i> (17 November 2009), Google Earth has taken to using
volunteers to correct their maps. John Kittle, an engineer from Decatur
Georgia, helped correct the Google map for his home town and said:</p>
        <blockquote>Seeing an error on a map is the kind of thing that
gnaws at me. By being able to fix it, I feel like the world is a better
place in a very small but measurable way. </blockquote>
        <p>That is not only nice way of expressing the ethos of
collaborative data curation, but it also suggests that instances of this
ethos occur with sufficient frequency to make it worthwhile to develop
frameworks that facilitate its exercise. </p>
        <p>Spellings and abbreviations of names in Early Modern drama
are very inconsistent, especially in speech prefixes. Mapping this
variance to standardized forms of names at the lemma level greatly
increases the query potential of plays. </p>
        <p>How many different words are used in Early Modern Drama and
with what frequency? You can answer that question quite precisely for
Shakespeare, who uses ~ 18,000 distinct lemmata, including proper names.
The machine will tell you that there are ~65,000 distinct lemmata in the
283 plays, but at least 20,000 of them are bogus lemmata that result
from incompletely transcribed words and minor variants in the spelling
of names and abbreviations. It would clearly be helpful for some
inquiries to have more precise data about the lexicon of Early Modern
drama.  This is an area where users can help.</p>
        <p>Errors of tokenization create special problems. It is certain
that the string "Christian nus creants" is meant to represent "Christian
miscreants." It is equally clear that "withothers" should be tokenized
as "with others," although you need to go to the original to determine
whether the error was the typesetter's or the transcriber's. Annolex
allows users to make suggestions for splitting or joining tokens. It is
agnostic about the question whether typographical errors of this kind
should be tacitly corrected in the transcription or explicitly marked. 
</p>
        <p>The manual correction of part-of-speech tags is probably an
acquired taste.  Corpus linguists live with error rates on the order of
3% and find that errors of that magnitude do not invalidate
quantitatively-based analyses. There are, however, some coarse errors
that are worth checking for in a given work. Do all the noun or proper
name tags represent nouns or proper names? Select the list of words in a
play that are not classified as nouns, adjectives, or verbs and look for
cases where a word clearly belongs in one of those classes. A handful of
such routines -- to be developed in a more elaborate tutorial -- are
likely to catch the coarsest and most consequential errors.  </p>

<h2>Future Directions</h2>
<p>There are many possible and desireable improvements to the current beta 
version of the software. A few that have occurred to us so far are:</p>  
<ul><li>Links to the page images digitized from microfilm that provided the
source for the upstream transcriptions. </li>
<li>Group correction operations for applying (or approving) the same correction to an entire
set of search results.</li>
<li>Import and export capabilities to facilitate loading arbitrary data sets
and extracting approved corrections for application to other systems.</li>
<li>More sophisticated validation of user input (e.g. recommending a lemma that
may have been intended when an unknown one is entered, but allowing an override
if creating a new one is genuinely desired).</li>
<li>Better user self-service features, such as the ability to register and
create one's own account.</li>
<li>External authentication, allowing integration with institutional user IDs.</li>
</ul>
</td></tr>
</table>
</div>


{% endblock %}